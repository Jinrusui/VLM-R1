import os
import re
import json
import base64
import ast
from openai import OpenAI
from PIL import Image
from datetime import datetime

# System prompt from the grpo_plan.py file
# SYSTEM_PROMPT = """
# You are an assistant designed to perform visual reasoning tasks and provide structured, detailed responses to the user's questions. You should carefully read and understand the questions and your responses should always include:
# - Your reasoning and analysis explicitly enclosed within <think> tags. Before presenting the visual information, carefully reason how best to represent it.
# - After your reasoning, clearly and objectively describe the visual information or image representation in textual, mathematical, symbolic, or other appropriate formats enclosed within <presentation> tags inside the <think> section.
# - Your final concise answer enclosed within <answer> tags.

# Follow this general structure for all your responses:
# <think>
# Clearly outline your reasoning process to determine how to represent the visual information or graphical content.
# <presentation>
# Provide the actual textual, mathematical, symbolic, or other appropriate format representation of the visual information, highlighting relevant features or key points necessary to understand the question or task.
# </presentation>
# Carefully outline your reasoning steps here. Provide clear and logical analysis, reflecting how you reached the conclusion from the presented visual or textual information.
# </think>
# <answer>
# Present a concise, accurate, and final answer derived from your reasoning.
# </answer>
# """
SYSTEM_PROMPT = """
You are an assistant designed to perform visual reasoning tasks and provide structured, detailed responses to the user's questions. You should carefully read and understand the questions, and your responses must always include:

- A clear and high-level reasoning introduction enclosed within `<think>` tags that outlines your initial understanding of the problem without revealing the final solution.
- A neutral and objective description of the visual information or graphical content enclosed within `<presentation>` tags inside the `<think>` section.
- A detailed, step-by-step logical analysis enclosed within the `<think>` tags after `<presentation>`, clearly showing how you derive your conclusion from the presented visual or textual information.
- Your concise final answer enclosed within `<answer>` tags.

Always follow this general structure for your responses:

<think>
Begin with high-level reasoning, identifying the key aspects or considerations of the task, without directly stating your final solution yet.

<presentation>
Clearly and objectively describe the visual information or graphical content, highlighting relevant features or key points necessary to understand the question or task, but without explicitly stating the final answer or solution.
</presentation>

Now, carefully outline your detailed reasoning steps here. Provide clear, logical analysis, explicitly showing how you reach the conclusion from the presented visual or textual information.
</think>

<answer>
Present a concise, accurate, and final answer derived from your detailed reasoning.
</answer>
"""
# Function to encode the image
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

# Function to verify the path generated by the model
def path_reward(completions, solution, **kwargs):
    def path_verifier(env_config, path):
        # 保持原有验证逻辑不变
        map_size = env_config["map_size"]
        start_position = env_config["start_position"]
        lake_positions = set(map(tuple, env_config["lake_positions"]))
        gift_position = tuple(env_config["gift_position"])
        
        position = tuple(start_position)
        moves = {
            "Left": (0, -1),
            "Right": (0, 1),
            "Up": (-1, 0),
            "Down": (1, 0)
        }
        
        for move in path:
            if move not in moves:
                return "invalid_move"
            
            dx, dy = moves[move]
            new_position = (position[0] + dx, position[1] + dy)
            
            if not (0 <= new_position[0] < map_size and 0 <= new_position[1] < map_size):
                return "out_of_bounds"
            
            position = new_position
            
            if position in lake_positions:
                return "failed"
            
            if position == gift_position:
                return "success"
        
        return "incomplete"

    # 保持与iou_reward一致的输入处理
    #contents = [completion[0]["content"] for completion in completions]
    contents = completions
    rewards = []
    current_time = datetime.now().strftime("%d-%H-%M-%S-%f")
    
    # 解析<answer>标签中的路径
    answer_tag_pattern = r'<answer>(.*?)</answer>'
    path_pattern = r'\[([^\[\]]+)\]'  # 匹配方括号内的内容

    for content, sol in zip(contents, solution):
        reward = 0.0
        try:
            # 双重解析：先提取<answer>内容，再解析路径列表
            content_answer_match = re.search(answer_tag_pattern, content, re.DOTALL)
            if content_answer_match:
                content_answer = content_answer_match.group(1).strip()
                
                # 使用ast安全解析列表
                path = ast.literal_eval(content_answer)
                
                # 验证路径
                result = path_verifier(sol, path)
                if result == "success":
                    reward = 1.0
        except Exception as e:
            pass  # 解析失败保持reward为0

        rewards.append(reward)
        
        # 保持与iou_reward一致的日志格式
        if os.getenv("DEBUG_MODE") == "true":
            log_path = os.getenv("LOG_PATH")
            with open(log_path, "a", encoding='utf-8') as f:
                f.write(f"------------- {current_time} Path reward: {reward} -------------\n")
                f.write(f"Content: {content}\n")
                f.write(f"Solution: {json.dumps(sol)}\n")
    
    return rewards




def format_reward(completions, **kwargs):
    """
    Reward function that checks if the completion follows the required structure:
    <think>
      ... (including <presentation>...</presentation>)
    </think>
    <answer>
      ...
    </answer>
    """
    # Regex pattern that enforces:
    # - A <think> block
    # - Which must contain a <presentation> block
    # - Then the </think> tag
    # - Followed by <answer> and </answer> tags
    pattern = (
        r"^<think>.*?<presentation>.*?</presentation>.*?</think>\s*"
        r"<answer>.*?</answer>$"
    )
    
    #completion_contents = [completion[0]["content"] for completion in completions]
    matches = [re.fullmatch(pattern, content, re.DOTALL) for content in completions]
    return [1.0 if match else 0.0 for match in matches]



def main():
    # Set up OpenAI client
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("Please set the OPENAI_API_KEY environment variable")
    
    client = OpenAI(api_key=api_key)
    
    # Test data
    test_data = {
        "problem": "Given an image of a FrozenLake grid, where the agent's position, safe tiles, lakes (holes), and the goal (gift) are visible, generate an optimal path from the agent to the gift, avoiding lakes. Your answer should be a list of moves in ['Up', 'Down', 'Left', 'Right'] format.",
        "solution": {
            "map_size": 4,
            "start_position": [0, 0],
            "lake_positions": [[1, 1], [1, 2], [2, 0], [2, 1], [3, 0], [3, 2]],
            "gift_position": [3, 3]
        },
        "image": "frozenlake_4x4_sample0.png"
    }
    
    # Image path
    image_root = os.environ.get("IMAGE_ROOT", r"E:\VLM-R1\frozenlake_samples2")
    image_path = os.path.join(image_root, test_data["image"])
    
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"Image not found: {image_path}")
    
    # Encode the image
    base64_image = encode_image(image_path)
    
    # Prepare the question
    question = test_data["problem"] + """First output the thinking process in <think> </think> tags and then output the final answer in <answer> </answer> tags. Output the final answer in JSON format."""
    
    # Make the API call using the OpenAI client
    response = client.chat.completions.create(
        model="gpt-4o",  # Use the appropriate model for vision tasks
        messages=[
            {
                "role": "system",
                "content": SYSTEM_PROMPT
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64_image}"
                        }
                    },
                    {
                        "type": "text",
                        "text": question
                    }
                ]
            }
        ]
    )
    
    # Extract the model's response
    model_response = response.choices[0].message.content
    
    print("\n=== Model Response ===")
    print(model_response)
    print(path_reward([model_response], [test_data["solution"]]))
    print(format_reward([model_response]))
        
    #     # Parse the answer part
    #     answer_pattern = r'<answer>(.*?)</answer>'
    #     answer_match = re.search(answer_pattern, model_response, re.DOTALL)
        
    #     if answer_match:
    #         answer_text = answer_match.group(1).strip()
            
    #         # Try to extract the path as a list
    #         try:
    #             # First try direct list parsing
    #             path = ast.literal_eval(answer_text)
    #             if not isinstance(path, list):
    #                 raise ValueError("Answer is not a list")
    #         except:
    #             # Fallback to regex extraction
    #             path_match = re.search(r'\[(.*?)\]', answer_text, re.DOTALL)
    #             if path_match:
    #                 path_str = path_match.group(1)
    #                 # Extract items from the comma-separated list
    #                 path = [item.strip().strip('"\'') for item in path_str.split(',')]
    #             else:
    #                 path = []
    #                 print("\nWarning: Could not parse path from answer")
            
    #         # Verify the path
    #         result, message = path_verifier(test_data["solution"], path)
            
    #         print("\n=== Path Verification ===")
    #         print(f"Path: {path}")
    #         print(f"Result: {result}")
    #         print(f"Message: {message}")
    #         print(f"Success: {'Yes' if result == 'success' else 'No'}")
            
    #         # Log the results
    #         log_dir = "logs"
    #         os.makedirs(log_dir, exist_ok=True)
    #         log_file = os.path.join(log_dir, f"test_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
            
    #         with open(log_file, 'w') as f:
    #             json.dump({
    #                 "test_data": test_data,
    #                 "model_response": model_response,
    #                 "extracted_path": path,
    #                 "verification_result": result,
    #                 "verification_message": message
    #             }, f, indent=2)
            
    #         print(f"\nResults saved to {log_file}")
    #     else:
    #         print("\nError: No answer tag found in the response")
    
    # except Exception as e:
    #     print(f"Error: {str(e)}")

if __name__ == "__main__":
    main()